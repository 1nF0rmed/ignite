version: 2.1

parameters:
  pytorch_stable_image:
    type: string
    # https://hub.docker.com/r/pytorch/pytorch/tags
    default: "pytorch/pytorch:1.6.0-cuda10.1-cudnn7-runtime"
  pytorch_stable_image_devel:
    type: string
    # https://hub.docker.com/r/pytorch/pytorch/tags
    default: "pytorch/pytorch:1.6.0-cuda10.1-cudnn7-devel"
  workingdir:
    type: string
    default: "/tmp/ignite"

# -------------------------------------------------------------------------------------
# Environments to run the jobs in
# -------------------------------------------------------------------------------------

one_gpu: &one_gpu
  docker:
    - image: << pipeline.parameters.pytorch_stable_image >>
  # https://circleci.com/product/features/resource-classes/#linux-vm
  resource_class: gpu.small

one_gpu_windows: &one_gpu_windows
  machine:
    resource_class: windows.gpu.nvidia.medium
    image: windows-server-2019-nvidia:stable
    shell: bash.exe

two_gpus: &two_gpus
  docker:
    - image: << pipeline.parameters.pytorch_stable_image >>
  # https://circleci.com/product/features/resource-classes/#linux-vm
  resource_class: gpu.medium

two_gpus_devel: &two_gpus_devel
  docker:
    - image: << pipeline.parameters.pytorch_stable_image_devel >>
  # https://circleci.com/product/features/resource-classes/#linux-vm
  resource_class: gpu.medium


# -------------------------------------------------------------------------------------
# Re-usable commands
# -------------------------------------------------------------------------------------

#pull_pytorch_stable_devel_image: &pull_pytorch_stable_devel_image
#  - run:
#      name: Pull PyTorch Stable Develop Image
#      command: |
#        docker pull << pipeline.parameters.pytorch_stable_image_devel >>

#run_pytorch_container: &run_pytorch_container
#  - run:
#      name: Start Pytorch container
#      environment:
#        wd: << pipeline.parameters.workingdir >>
#      command: |
#        docker run --gpus=all --rm -itd --shm-size 16G -v ${wd}:/ignite -w /ignite --name pthd << pipeline.parameters.pytorch_stable_image >>
#        docker exec -it pthd nvidia-smi
#        docker exec -it pthd ls

#run_pytorch_devel_container: &run_pytorch_devel_container
#  - run:
#      name: Start Pytorch dev container
#      environment:
#        wd: << pipeline.parameters.workingdir >>
#      command: |
#        docker run --gpus=all --rm -itd --shm-size 16G -v ${wd}:/ignite -w /ignite --name pthd << pipeline.parameters.pytorch_stable_image_devel >>
#        docker exec -it pthd nvidia-smi
#        docker exec -it pthd ls

install_dependencies: &install_dependencies
  - run:
      name: Install dependencies
      command: |
        nvidia-smi
        pip install -r requirements-dev.txt
        pip install .

# -------------------------------------------------------------------------------------
# Jobs to run
# -------------------------------------------------------------------------------------
jobs:
  one_gpu_tests:
    <<: *one_gpu

    working_directory: << pipeline.parameters.workingdir >>

    steps:
      - checkout
      - run:
          name: Trigger job if modified
          command: |
            bash .circleci/trigger_if_modified.sh "^(ignite|tests|examples|\.circleci).*"
      - <<: *install_dependencies
      - run:
          name: Run GPU Unit Tests and Examples
          command: |

            # pytest on cuda
            bash tests/run_gpu_tests.sh

            # MNIST tests

            # 1) mnist.py
            CUDA_VISIBLE_DEVICES=0 python examples/mnist/mnist.py --epochs=1

            # 2) mnist_with_visdom.py
            python -c "from visdom.server import download_scripts; download_scripts()"
            python -m visdom.server
            sleep 10
            python examples/mnist/mnist_with_visdom.py --epochs=1

            # 3.1) mnist_with_tensorboard.py with tbX
            CUDA_VISIBLE_DEVICES=0 python examples/mnist/mnist_with_tensorboard.py --epochs=1

            # uninstall tensorboardX
            pip uninstall -y tensorboardX

            # 3.2) mnist_with_tensorboard.py with native torch tb
            CUDA_VISIBLE_DEVICES=0 python examples/mnist/mnist_with_tensorboard.py --epochs=1

            # 4) mnist_save_resume_engine.py
            # save
            CUDA_VISIBLE_DEVICES=0 python examples/mnist/mnist_save_resume_engine.py --epochs=2 --crash_iteration 1100
            # resume
            CUDA_VISIBLE_DEVICES=0 python examples/mnist/mnist_save_resume_engine.py --epochs=2 --resume_from=/tmp/mnist_save_resume/checkpoint_1.pt

      - run:
          name: Codecov upload
          command: |
            bash <(curl -s https://codecov.io/bash) -Z -F gpu

  one_gpu_windows_tests:
    <<: *one_gpu_windows

    working_directory: << pipeline.parameters.workingdir >>

    steps:
      - checkout
      - run:
          name: Trigger job if modified
          command: |
            bash .circleci/trigger_if_modified.sh "^(ignite|tests|examples|\.circleci).*"

      - run:
          name: Install dependencies
          command: |
            conda --version
            conda install -y pytorch torchvision cudatoolkit=10.1 -c pytorch
            pip install -r requirements-dev.txt
            pip install .

      - run:
          name: Run GPU Unit Tests
          command: |
            # pytest on cuda
            SKIP_DISTRIB_TESTS=1 bash tests/run_gpu_tests.sh

  two_gpus_tests:
    <<: *two_gpus

    working_directory: << pipeline.parameters.workingdir >>

    steps:
      - checkout
      - run:
          name: Trigger job if modified
          command: |
            bash .circleci/trigger_if_modified.sh "^(ignite|tests|examples|\.circleci).*"
      - <<: *install_dependencies
      - run:
          name: Run 1 Node 2 GPUs Unit Tests
          command: |
            bash tests/run_gpu_tests.sh 2

      - run:
          name: Codecov upload
          command: |
            bash <(curl -s https://codecov.io/bash) -Z -F gpu-2

  two_gpus_check_dist_cifar10_example:
    <<: *two_gpus

    working_directory: << pipeline.parameters.workingdir >>

    steps:
      - checkout
      - run:
          name: Trigger job if modified
          command: |
            bash .circleci/trigger_if_modified.sh "^(ignite|tests|examples|\.circleci).*"
      - <<: *install_dependencies
      - run:
          name: "Install additional example dependencies"
          command: |
            pip install fire
      - run:
          name: "Run without backend"
          command: |
            export example_path="examples/contrib/cifar10"
            # initial run
            CI=1 python ${example_path}/main.py run --stop_iteration=500

            # resume
            export resume_opt="--resume-from=/tmp/output-cifar10/resnet18_backend-None-1_stop-on-500/training_checkpoint_400.pt"
            CI=1 python ${example_path}/main.py run --num_epochs=7 ${resume_opt}

      - run:
          name: "Run with NCCL backend using torch dist launch"
          command: |
            export example_path="examples/contrib/cifar10"
            # initial run
            export stop_cmd="--stop_iteration=500"
            CI=1 python -u -m torch.distributed.launch --nproc_per_node=2 --use_env ${example_path}/main.py run --backend=nccl --stop_iteration=500
            # resume
            export resume_opt="--resume-from=/tmp/output-cifar10/resnet18_backend-nccl-2_stop-on-500/training_checkpoint_400.pt"
            CI=1 python -u -m torch.distributed.launch --nproc_per_node=2 --use_env ${example_path}/main.py run --backend=nccl --num_epochs=7 ${resume_opt}

      - run:
          name: "Run with NCCL backend using spawn"
          command: |
            export example_path="examples/contrib/cifar10"
            # initial run
            CI=1 python -u ${example_path}/main.py run --backend=nccl --nproc_per_node=2 --stop_iteration=500

            # resume
            export resume_opt="--resume-from=/tmp/output-cifar10/resnet18_backend-nccl-2_stop-on-500/training_checkpoint_400.pt"
            CI=1 python -u ${example_path}/main.py run --backend=nccl --nproc_per_node=2 --num_epochs=7 ${resume_opt}

  two_gpus_hvd_tests:
    <<: *two_gpus_devel

    working_directory: << pipeline.parameters.workingdir >>

    steps:
      - checkout
      - run:
          name: Trigger job if modified
          command: |
            bash .circleci/trigger_if_modified.sh "^(ignite|tests|examples|\.circleci).*"
      - <<: *install_dependencies
      - run:
          name: "Install Horovod with NCCL GPU ops"
          command: |

            # Following https://github.com/horovod/horovod/blob/master/Dockerfile.test.gpu
            # and https://github.com/horovod/horovod/issues/1944#issuecomment-628192778
            apt-get update && apt-get install -y git
            git clone --recursive https://github.com/horovod/horovod.git /horovod && cd /horovod && python setup.py sdist
            conda install -y cmake=3.16 nccl=2.7 -c conda-forge
            cd /horovod && HOROVOD_GPU_OPERATIONS=NCCL HOROVOD_NCCL_LINK=SHARED HOROVOD_WITHOUT_MPI=1 HOROVOD_WITH_PYTORCH=1 pip install -v $(ls /horovod/dist/horovod-*.tar.gz) && ldconfig
            horovodrun --check-build

      - run:
          name: Run 1 Node 2 GPUs Unit Tests
          command: |
            bash tests/run_gpu_tests.sh

            # no CUDA devices Horovod tests
            CUDA_VISIBLE_DEVICES="" pytest --cov ignite --cov-append --cov-report term-missing --cov-report xml -vvv tests/ -m distributed

      - run:
          name: Codecov upload
          command: |
            bash <(curl -s https://codecov.io/bash) -Z -F gpu-2-hvd

      - run:
          name: "Check CIFAR10 using horovodrun"
          command: |
            pip install fire
            export example_path="examples/contrib/cifar10"
            # initial run
            cd ${example_path} && CI=1 horovodrun -np 2 python -u main.py run --backend=horovod --stop_iteration=500

            # resume
            export resume_opt="--resume-from=/tmp/output-cifar10/resnet18_backend-horovod-2_stop-on-500/training_checkpoint_400.pt"
            cd ${example_path} && CI=1 horovodrun -np 2 python -u main.py run --backend=horovod --num_epochs=7 ${resume_opt}

      - run:
          name: "Check CIFAR10 using spawn"
          command: |
            export example_path="examples/contrib/cifar10"
            # initial run
            cd ${example_path} && CI=1 python -u main.py run --backend=horovod --nproc_per_node=2 --stop_iteration=500

            # resume
            export resume_opt="--resume-from=/tmp/output-cifar10/resnet18_backend-horovod-2_stop-on-500/training_checkpoint_400.pt"
            cd ${example_path} && CI=1 python -u main.py run --backend=horovod --nproc_per_node=2 --num_epochs=7 ${resume_opt}

# -------------------------------------------------------------------------------------
# Workflows
# -------------------------------------------------------------------------------------
workflows:
  version: 2
  gpu_tests:
    jobs:
      - one_gpu_tests
      - one_gpu_windows_tests
      - two_gpus_tests
      - two_gpus_check_dist_cifar10_example
      - two_gpus_hvd_tests
